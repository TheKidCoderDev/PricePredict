{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e729defe2c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "\n",
    "number_of_inputs = 63\n",
    "number_of_outputs = 1\n",
    "learning_rate=0.0005\n",
    "training_epochs=50\n",
    "display_step=5\n",
    "\n",
    "layer_1_nodes=50\n",
    "layer_2_nodes=100\n",
    "layer_3_nodes=50\n",
    "\n",
    "RUN_NAME=str(datetime.datetime.utcnow()).replace(\" \", \"_\")\n",
    "\n",
    "def readData():\n",
    "    \n",
    "    global x_scaled_training, y_scaled_training, x_scaled_testing, y_scaled_testing, x_scaler, y_scaler, x_train, x_test, y_train, y_test\n",
    "    \n",
    "    dataFrame = pd.read_csv(\"house_data.csv\")\n",
    "    \n",
    "    del dataFrame[\"house_number\"]\n",
    "    del dataFrame['street_name']\n",
    "    del dataFrame['unit_number']\n",
    "    del dataFrame['zip_code']\n",
    "\n",
    "    featuresDataFrame = pd.get_dummies(dataFrame, columns=[\"city\", \"garage_type\"])\n",
    "    \n",
    "    del featuresDataFrame['sale_price']\n",
    "    \n",
    "    global x_train, x_test, y_train, y_test\n",
    "    \n",
    "    x=featuresDataFrame.as_matrix()\n",
    "    y=dataFrame[['sale_price']].as_matrix()\n",
    "    \n",
    "    x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    x_scaled_training = x_scaler.fit_transform(x_train)\n",
    "    y_scaled_training = y_scaler.fit_transform(y_train)\n",
    "    \n",
    "    x_scaled_testing = x_scaler.transform(x_test)\n",
    "    y_scaled_testing = y_scaler.transform(y_test)\n",
    "    \n",
    "#     print(len(x_train[0]), end=\"\\n\\n\")\n",
    "#     print(x_scaled_training[:5], end=\"\\n\\n\")\n",
    "#     print(\"The scale on X_data is: \\n\", x_scaler.scale_, \"\\nWith adjustments of: \\n\", x_scaler.min_)\n",
    "#     print(\"\\nThe scale on Y_data is: \\n\", y_scaler.scale_, \"\\nWith adjustments of: \\n\", y_scaler.min_)\n",
    "#     print(\"\\nNote: Y values were scaled by multiplying by {:.10f} and adding {:.4f}\".format(Y_scaler.scale_[0], y_scaler.min_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    global number_of_inputs, number_of_outputs, learning_rate, training_epochs, display_step, layer_1_nodes, layer_2_nodes, layer_3_nodes\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        x = tf.placeholder(tf.float32, shape=(None, number_of_inputs), name='x')\n",
    "        \n",
    "    with tf.variable_scope('layer_1'):\n",
    "        weights = tf.get_variable(name='weights_1', shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name='biases_1', shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "        # Using relu and matrix multiplication to define the activation function\n",
    "        layer_1_output = tf.nn.relu(tf.matmul(x, weights) + biases)\n",
    "        \n",
    "    with tf.variable_scope('layer_2'):\n",
    "        weights = tf.get_variable(name='weights_2', shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name='biases_2', shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "        # Using relu and matrix multiplication to define the activation function\n",
    "        layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "        \n",
    "    with tf.variable_scope('layer_3'):\n",
    "        weights = tf.get_variable(name='weights_3', shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name='biases_3', shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "        # Using relu and matrix multiplication to define the activation function\n",
    "        layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "        \n",
    "    with tf.variable_scope('output'):\n",
    "        weights = tf.get_variable(name='weights_4', shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name='biases_4', shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "        # Using relu and matrix multiplication to define the activation function\n",
    "        output = tf.nn.relu(tf.matmul(layer_3_output, weights) + biases, name=\"output\")\n",
    "        \n",
    "    with tf.variable_scope('cost'):\n",
    "        y=tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        cost=tf.reduce_mean(tf.squared_difference(output, y))\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "        \n",
    "    with tf.variable_scope('logging'):\n",
    "        tf.summary.scalar('current_cost', cost)\n",
    "        log = tf.summary.merge_all()\n",
    "        \n",
    "    saver=tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        training_writer = tf.summary.FileWriter(('./Logs/{}/training'.format(RUN_NAME)), session.graph)\n",
    "        testing_writer = tf.summary.FileWriter(('./Logs/{}/testing'.format(RUN_NAME)), session.graph)\n",
    "        \n",
    "        for i in range(training_epochs):\n",
    "            session.run(optimizer, feed_dict={x : x_scaled_training, y : y_scaled_training})\n",
    "            training_cost, training_prediction, training_log=session.run([cost, output, log], feed_dict={x: x_scaled_training, y: y_scaled_training})\n",
    "            testing_cost, testing_prediction, testing_log=session.run([cost, output, log], feed_dict={x: x_scaled_testing, y: y_scaled_testing})\n",
    "            \n",
    "            training_writer.add_summary(training_log, i)\n",
    "            training_writer.flush()\n",
    "            testing_writer.add_summary(testing_log, i)\n",
    "            testing_writer.flush()\n",
    "            \n",
    "            print(\"Training Pass: {}\".format(i))\n",
    "            print(\"Training Cost:\", training_cost)\n",
    "            print(\"Testing Cost: \", testing_cost)\n",
    "            #print(\"Training Prediction:\", training_prediction)\n",
    "        print(\"Training Complete\")\n",
    "        save_path=saver.save(session, 'Models/saved_model.ckpy')\n",
    "        print(\"Model Saved at {}\".format(save_path))\n",
    "        \n",
    "        # Now that the neural network is trained, let's use it to make predictions for our test data.\n",
    "        # Pass in the X testing data and run the \"prediciton\" operation\n",
    "        y_predicted_scaled = session.run(output, feed_dict={x: x_scaled_testing})\n",
    "    \n",
    "        # Unscale the data back to it's original units (dollars)\n",
    "        y_predicted = y_scaler.inverse_transform(y_predicted_scaled)\n",
    "    \n",
    "        house_real_pricing = y_test[:4]\n",
    "        predicted_pricing = y_predicted[:4]\n",
    "    \n",
    "        print(\"The actual house price of House_1 was $\\n{}\".format(house_real_pricing))\n",
    "        print(\"Our neural network predicted prices of $\\n{}\".format(predicted_pricing))\n",
    "\n",
    "def main():                                                                    \n",
    "    readData()\n",
    "    trainModel()\n",
    "                                                                    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
