{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "\n",
    "number_of_inputs = 63\n",
    "number_of_outputs = 1\n",
    "learning_rate=0.0001\n",
    "training_epochs=50\n",
    "display_step=5\n",
    "\n",
    "layer_1_nodes=50\n",
    "layer_2_nodes=100\n",
    "layer_3_nodes=50\n",
    "\n",
    "RUN_NAME=str(datetime.datetime.utcnow()).replace(\" \", \"_\")\n",
    "\n",
    "def readData():\n",
    "    \n",
    "    global x_scaled_training, y_scaled_training, x_scaled_testing, y_scaled_testing, x_scaler, y_scaler\n",
    "    \n",
    "    dataFrame = pd.read_csv(\"house_data.csv\")\n",
    "    \n",
    "    del dataFrame[\"house_number\"]\n",
    "    del dataFrame['street_name']\n",
    "    del dataFrame['unit_number']\n",
    "    del dataFrame['zip_code']\n",
    "\n",
    "    featuresDataFrame = pd.get_dummies(dataFrame, columns=[\"city\", \"garage_type\"])\n",
    "    \n",
    "    del featuresDataFrame['sale_price']\n",
    "    \n",
    "    global x_train, x_test, y_train, y_test\n",
    "    \n",
    "    x=featuresDataFrame.as_matrix()\n",
    "    y=dataFrame[['sale_price']].as_matrix()\n",
    "    \n",
    "    x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    x_scaled_training = x_scaler.fit_transform(x_train)\n",
    "    y_scaled_training = y_scaler.fit_transform(y_train)\n",
    "    \n",
    "    x_scaled_testing = x_scaler.transform(x_test)\n",
    "    y_scaled_testing = y_scaler.transform(y_test)\n",
    "    \n",
    "#     print(len(x_train[0]), end=\"\\n\\n\")\n",
    "#     print(x_scaled_training[:5], end=\"\\n\\n\")\n",
    "#     print(\"The scale on X_data is: \\n\", x_scaler.scale_, \"\\nWith adjustments of: \\n\", x_scaler.min_)\n",
    "#     print(\"\\nThe scale on Y_data is: \\n\", y_scaler.scale_, \"\\nWith adjustments of: \\n\", y_scaler.min_)\n",
    "#     print(\"\\nNote: Y values were scaled by multiplying by {:.10f} and adding {:.4f}\".format(Y_scaler.scale_[0], y_scaler.min_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milse113/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/milse113/anaconda3/envs/AI/lib/python3.6/site-packages/ipykernel_launcher.py:37: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/milse113/anaconda3/envs/AI/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pass: 0\n",
      "Training Cost: 15.26651\n",
      "Testing Cost:  15.372756\n",
      "Training Pass: 1\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 2\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 3\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 4\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 5\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 6\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 7\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 8\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 9\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 10\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n",
      "Training Pass: 11\n",
      "Training Cost: 0.0022228176\n",
      "Testing Cost:  0.002534317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ee1c365aaf16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ee1c365aaf16>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mreadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ee1c365aaf16>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx_scaled_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0my_scaled_training\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mtraining_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_scaled_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_scaled_training\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mtesting_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_scaled_testing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_scaled_testing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def trainModel():\n",
    "    global number_of_inputs, number_of_outputs, learning_rate, training_epochs, display_step, layer_1_nodes, layer_2_nodes, layer_3_nodes\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        x = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "        \n",
    "    with tf.variable_scope('layer_1'):\n",
    "        weights = tf.get_variable(name='weights_1', shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name='biases_1', shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "        # Using relu and matrix multiplication to define the activation function\n",
    "        layer_1_output = tf.nn.relu(tf.matmul(x, weights) + biases)\n",
    "        \n",
    "    with tf.variable_scope('layer_2'):\n",
    "        weights = tf.get_variable(name='weights_2', shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name='biases_2', shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "        # Using relu and matrix multiplication to define the activation function\n",
    "        layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "        \n",
    "    with tf.variable_scope('layer_3'):\n",
    "        weights = tf.get_variable(name='weights_3', shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name='biases_3', shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "        # Using relu and matrix multiplication to define the activation function\n",
    "        layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "        \n",
    "    with tf.variable_scope('output'):\n",
    "        weights = tf.get_variable(name='weights_4', shape=[layer_3_nodes, number_of_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name='biases_4', shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "        # Using relu and matrix multiplication to define the activation function\n",
    "        output = tf.nn.relu(tf.matmul(layer_3_output, weights) + biases)\n",
    "        \n",
    "    with tf.variable_scope('cost'):\n",
    "        y=tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        cost=tf.reduce_mean(tf.squared_difference(output, y))\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "        \n",
    "    with tf.variable_scope('logging'):\n",
    "        tf.summary.scalar('current_cost', cost)\n",
    "        log = tf.summary.merge_all()\n",
    "        \n",
    "    saver=tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        training_writer = tf.summary.FileWriter(('./Logs/{}/training'.format(RUN_NAME)), session.graph)\n",
    "        testing_writer = tf.summary.FileWriter(('./Logs/{}/testing'.format(RUN_NAME)), session.graph)\n",
    "        \n",
    "        for i in range(training_epochs):\n",
    "            session.run(optimizer, feed_dict={x : x_scaled_training, y : y_scaled_training})\n",
    "            training_cost, training_prediction, training_log=session.run([cost, output, log], feed_dict={x: x_scaled_training, y: y_scaled_training})\n",
    "            testing_cost, testing_prediction, testing_log=session.run([cost, output, log], feed_dict={x: x_scaled_testing, y: y_scaled_testing})\n",
    "            \n",
    "            training_writer.add_summary(training_log, i)\n",
    "            training_writer.flush()\n",
    "            testing_writer.add_summary(testing_log, i)\n",
    "            testing_writer.flush()\n",
    "            \n",
    "            print(\"Training Pass: {}\".format(i))\n",
    "            print(\"Training Cost:\", training_cost)\n",
    "            print(\"Testing Cost: \", testing_cost)\n",
    "            #print(\"Training Prediction:\", training_prediction)\n",
    "        print(\"Training Complete\")\n",
    "        save_path=saver.save(session, 'Models/saved_model.ckpy')\n",
    "        print(\"Model Saved at {}\".format(save_path))\n",
    "        \n",
    "        # Now that the neural network is trained, let's use it to make predictions for our test data.\n",
    "        # Pass in the X testing data and run the \"prediciton\" operation\n",
    "        y_predicted_scaled = session.run(prediction, feed_dict={x: x_scaled_testing})\n",
    "    \n",
    "        # Unscale the data back to it's original units (dollars)\n",
    "        y_predicted = y_scaler.inverse_transform(y_predicted_scaled)\n",
    "    \n",
    "        house_real_pricing = y_testing[:4]\n",
    "        predicted_pricing = y_predicted[:4]\n",
    "    \n",
    "        print(\"The actual house price of House_1 was $\\n{}\".format(house_real_pricing))\n",
    "        print(\"Our neural network predicted prices of $\\n{}\".format(predicted_pricing))\n",
    "\n",
    "def main():                                                                    \n",
    "    readData()\n",
    "    trainModel()\n",
    "                                                                    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
